{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04778fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137e6ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data is in excel format so, read data as 'read_excel'\n",
    "train = pd.read_excel('Data_Train.xlsx')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6097b1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_excel('Test_set.xlsx')\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1e620c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training dataset shape:', train.shape)\n",
    "print('Test dataset shape:', test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a465e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1857c448",
   "metadata": {},
   "outputs": [],
   "source": [
    "train[train['Total_Stops'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a34861d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train[train['Route'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32de79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train=train.dropna(axis=0, how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b98efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f1db4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71298ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b464f5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First we consider Duration column\n",
    "train[\"Duration\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e447009",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting 'Duration' column into a list\n",
    "duration_train = list(train[\"Duration\"])\n",
    "duration_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e244c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply loop to separate hours from minutes\n",
    "#.split() method splits a string into a list\n",
    "#also, hour is represented by 'h' and minute by'm'\n",
    "#.strip() method returns a copy of the string by removing both the leading and the trailing characters\n",
    "\n",
    "for i in range(len(duration_train)):\n",
    "    if len(duration_train[i].split()) != 2:   \n",
    "        if \"h\" in duration_train[i]:\n",
    "            duration_train[i] = duration_train[i].strip() + ' 0m'  # add 0 minute \n",
    "        else:\n",
    "            duration_train[i] = '0h '+ duration_train[i]           # add 0 hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4770c834",
   "metadata": {},
   "outputs": [],
   "source": [
    "duration_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3e5e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "duration_hours = []\n",
    "duration_mins = []\n",
    "for i in range(len(duration_train)):\n",
    "    duration_hours.append(int(duration_train[i].split(sep = \"h\")[0]))\n",
    "    duration_mins.append(int(duration_train[i].split(sep = \"m\")[0].split()[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f466d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Duration_hrs'] = duration_hours\n",
    "train['Duration_hrs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cec3e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Duration_mins'] = duration_mins\n",
    "train['Duration_mins']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7561b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop('Duration', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23ce8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#first we consider 'Date_of_Journey'\n",
    "train['Day_of_Journey']=pd.to_datetime(train['Date_of_Journey'], format='%d/%m/%Y').dt.day\n",
    "train['Month_of_Journey']=pd.to_datetime(train['Date_of_Journey'], format='%d/%m/%Y').dt.month\n",
    "train.drop('Date_of_Journey', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbce91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, we need to take care of Dep_Time\n",
    "train['Dep_hr'] = pd.to_datetime(train['Dep_Time']).dt.hour\n",
    "train['Dep_min'] = pd.to_datetime(train['Dep_Time']).dt.minute\n",
    "train.drop('Dep_Time', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1191ff20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now, we take care of Arrival_Time\n",
    "train['Arrival_hr'] = pd.to_datetime(train['Arrival_Time']).dt.hour\n",
    "train['Arrival_min'] = pd.to_datetime(train['Arrival_Time']).dt.minute\n",
    "train.drop('Arrival_Time', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e926ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train dataset shape:', train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fff31f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ac613f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Taking care of Airline column\n",
    "print(train['Airline'].unique())\n",
    "#print(train['Airline'].nunique())\n",
    "print(train['Airline'].value_counts())\n",
    "sns.catplot(y = 'Price', x = 'Airline', data = train.sort_values('Price', ascending = False), \n",
    "            kind='box', height = 4, aspect = 3, orient='v')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8501e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train.shape)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a239614e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#select categorical variables from then dataset, and then implement categorical encoding for nominal variables\n",
    "Airline=train[['Airline']]\n",
    "Airline=pd.get_dummies(Airline, drop_first=True)\n",
    "Airline.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960d7cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "Source=train[['Source']]\n",
    "Source=pd.get_dummies(Source, drop_first= True)\n",
    "Source.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c61bbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Destination=train[['Destination']]\n",
    "Destination=pd.get_dummies(Destination, drop_first= True)\n",
    "Destination.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf444c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate dataset with Airline, Source, Destination, Additional_Info\n",
    "\n",
    "train = pd.concat([train, Airline, Source, Destination], axis = 1)\n",
    "\n",
    "#Dropping the non-encoded Airline, Source, Destination variables\n",
    "train.drop(['Airline', 'Source', 'Destination', 'Additional_Info', 'Route'], axis = 1, inplace = True)\n",
    "#dropping route column as we have a stop column which basically covers the entire zest of it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e9f6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing Total_Stops\n",
    "train.replace({\"non-stop\": 0, \"1 stop\": 1, \"2 stops\": 2, \"3 stops\": 3, \"4 stops\": 4}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a972f51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train.shape)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb49523",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First we consider Duration column\n",
    "test[\"Duration\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888a59c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting 'Duration' column into a list\n",
    "duration_test = list(test[\"Duration\"])\n",
    "duration_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7444fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply loop to separate hours from minutes\n",
    "#.split() method splits a string into a list\n",
    "#also, hour is represented by 'h' and minute by'm'\n",
    "#.strip() method returns a copy of the string by removing both the leading and the trailing characters\n",
    "for i in range(len(duration_test)):\n",
    "    if len(duration_test[i].split()) != 2:   \n",
    "        if \"h\" in duration_test[i]:\n",
    "            duration_test[i] = duration_test[i].strip() + ' 0m'  # add 0 minute \n",
    "        else:\n",
    "            duration_test[i] = '0h '+ duration_test[i]           # add 0 hour\n",
    "            \n",
    "duration_hours = []\n",
    "duration_mins = []\n",
    "for i in range(len(duration_test)):\n",
    "    duration_hours.append(int(duration_test[i].split(sep = \"h\")[0]))\n",
    "    duration_mins.append(int(duration_test[i].split(sep = \"m\")[0].split()[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c6f2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "duration_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e321d995",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Duration_hrs'] = duration_hours\n",
    "test['Duration_hrs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb4e21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Duration_mins'] = duration_mins\n",
    "test['Duration_mins']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328d2ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.drop('Duration', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4261922",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Day_of_Journey']=pd.to_datetime(test['Date_of_Journey'], format='%d/%m/%Y').dt.day\n",
    "test['Month_of_Journey']=pd.to_datetime(test['Date_of_Journey'], format='%d/%m/%Y').dt.month\n",
    "test.drop('Date_of_Journey', axis = 1, inplace = True)\n",
    "\n",
    "test['Dep_hr'] = pd.to_datetime(test['Dep_Time']).dt.hour\n",
    "test['Dep_min'] = pd.to_datetime(test['Dep_Time']).dt.minute\n",
    "test.drop('Dep_Time', axis = 1, inplace = True)\n",
    "\n",
    "test['Arrival_hr'] = pd.to_datetime(test['Arrival_Time']).dt.hour\n",
    "test['Arrival_min'] = pd.to_datetime(test['Arrival_Time']).dt.minute\n",
    "test.drop('Arrival_Time', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a064e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Test dataset shape:', test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc8a9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#select categorical variables from then dataset, and then implement categorical encoding for nominal variables\n",
    "Airline=test[['Airline']]\n",
    "Airline=pd.get_dummies(Airline, drop_first=True)\n",
    "\n",
    "Source=test[['Source']]\n",
    "Source=pd.get_dummies(Source, drop_first= True)\n",
    "\n",
    "Destination=test[['Destination']]\n",
    "Destination=pd.get_dummies(Destination, drop_first= True)\n",
    "\n",
    "\n",
    "# Concatenate dataset with Airline, Source, Destination, Additional_Info\n",
    "test= pd.concat([test, Airline, Source, Destination], axis = 1)\n",
    "\n",
    "#Dropping the non-encoded Airline, Source, Destination variables\n",
    "test.drop(['Airline', 'Source', 'Destination', 'Additional_Info', 'Route'], axis = 1, inplace = True)\n",
    "#dropping route column as we have a stop column which basically covers the entire zest of it \n",
    "\n",
    "\n",
    "#Let's take care of Total_Stops\n",
    "test.replace({\"non-stop\": 0, \"1 stop\": 1, \"2 stops\": 2, \"3 stops\": 3, \"4 stops\": 4}, inplace = True)\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "test['Total_Stops'] = encoder.fit_transform(test['Total_Stops'])\n",
    "\n",
    "print(test.shape)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399a4546",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d932553",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101fd7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train.drop(labels=['Airline_Trujet'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24110fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a371d23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "price=train.Price\n",
    "train.drop('Price', axis=1, inplace=True)\n",
    "train=train.join(price)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf36a688",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.loc[:, ['Total_Stops', 'Duration_hrs', 'Duration_mins',\n",
    "       'Day_of_Journey', 'Month_of_Journey', 'Dep_hr', 'Dep_min', 'Arrival_hr',\n",
    "       'Arrival_min', 'Airline_Air India', 'Airline_GoAir', 'Airline_IndiGo',\n",
    "       'Airline_Jet Airways', 'Airline_Jet Airways Business',\n",
    "       'Airline_Multiple carriers',\n",
    "       'Airline_Multiple carriers Premium economy', 'Airline_SpiceJet',\n",
    "       'Airline_Trujet', 'Airline_Vistara', 'Airline_Vistara Premium economy',\n",
    "       'Source_Chennai', 'Source_Delhi', 'Source_Kolkata', 'Source_Mumbai',\n",
    "       'Destination_Cochin', 'Destination_Delhi', 'Destination_Hyderabad',\n",
    "       'Destination_Kolkata', 'Destination_New Delhi']]\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f058429",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train.iloc[:, -1]\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc6a8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Important feature using ExtraTreesRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "selection = ExtraTreesRegressor()\n",
    "selection.fit(X, y)\n",
    "\n",
    "#bar graph of feature importances \n",
    "plt.figure(figsize = (10,8))\n",
    "feat_importances = pd.Series(selection.feature_importances_, index=X.columns)\n",
    "feat_importances.nlargest(20).plot(kind='barh')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625c3933",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "kfold = StratifiedKFold(n_splits=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0680ac04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train Test Split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size = 0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9279db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Linear Regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lin_reg=LinearRegression()\n",
    "lin_reg.fit(X_train, y_train)\n",
    "y_pred=lin_reg.predict(X_test)\n",
    "\n",
    "print(\"Linear Regression Score on Training set is\",lin_reg.score(X_train, y_train))#Training Accuracy\n",
    "print(\"Linear Regression Score on Test Set is\",lin_reg.score(X_test, y_test))#Testing Accuracy\n",
    "\n",
    "accuracies = cross_val_score(lin_reg, X_train, y_train, cv = kfold)\n",
    "print(accuracies)\n",
    "print(\"Accuracy: {:.2f} %\".format(accuracies.mean()*100))\n",
    "print(\"Standard Deviation: {:.2f} %\".format(accuracies.std()*100))\n",
    "\n",
    "mae=mean_absolute_error(y_pred, y_test)\n",
    "print(\"Mean Absolute Error:\" , mae)\n",
    "\n",
    "mse=mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\" , mse)\n",
    "\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n",
    "\n",
    "print('The r2_score is', metrics.r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90391787",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision Tree Regressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "dt_reg = DecisionTreeRegressor(random_state = 0)\n",
    "dt_reg.fit(X_train, y_train)\n",
    "y_pred=dt_reg.predict(X_test)\n",
    "\n",
    "print(\"Decision Tree Score on Training set is\",dt_reg.score(X_train, y_train))#Training Accuracy\n",
    "print(\"Decision Tree Score on Test Set is\",dt_reg.score(X_test, y_test))#Testing Accuracy\n",
    "\n",
    "accuracies = cross_val_score(dt_reg, X_train, y_train, cv = kfold)\n",
    "print(accuracies)\n",
    "print(\"Accuracy: {:.2f} %\".format(accuracies.mean()*100))\n",
    "print(\"Standard Deviation: {:.2f} %\".format(accuracies.std()*100))\n",
    "\n",
    "mae=mean_absolute_error(y_pred, y_test)\n",
    "print(\"Mean Absolute Error:\" , mae)\n",
    "\n",
    "mse=mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\" , mse)\n",
    "\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n",
    "\n",
    "print('The r2_score is', metrics.r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e73f350",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest Regression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf_reg = RandomForestRegressor(n_estimators=400,min_samples_split=15,min_samples_leaf=2,\n",
    "max_features='auto', max_depth=30)\n",
    "rf_reg.fit(X_train, y_train)\n",
    "y_pred=rf_reg.predict(X_test)\n",
    "\n",
    "print(\"Random Forest Score on Training set is\",rf_reg.score(X_train, y_train))#Training Accuracy\n",
    "print(\"Random Forest Score on Test Set is\",rf_reg.score(X_test, y_test))#Testing Accuracy\n",
    "\n",
    "accuracies = cross_val_score(rf_reg, X_train, y_train, cv = kfold)\n",
    "print(accuracies)\n",
    "print(\"Accuracy: {:.2f} %\".format(accuracies.mean()*100))\n",
    "print(\"Standard Deviation: {:.2f} %\".format(accuracies.std()*100))\n",
    "\n",
    "mae=mean_absolute_error(y_pred, y_test)\n",
    "print(\"Mean Absolute Error:\" , mae)\n",
    "\n",
    "mse=mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\" , mse)\n",
    "\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n",
    "\n",
    "print('The r2_score is', metrics.r2_score(y_test, y_pred))\n",
    "\n",
    "sns.distplot(y_test-y_pred)\n",
    "plt.show()\n",
    "\n",
    "plt.scatter(y_test, y_pred, alpha = 0.5)\n",
    "plt.xlabel(\"y_test\")\n",
    "plt.ylabel(\"y_pred\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd9db6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
