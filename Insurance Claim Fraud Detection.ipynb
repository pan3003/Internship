{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4652965",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install joypy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cbdaa48",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install bubbly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24b6380",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# for some basic operations\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import joypy\n",
    "\n",
    "# for visualizations\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pandas import plotting\n",
    "from pandas.plotting import parallel_coordinates\n",
    "\n",
    "# for interactive visualizations\n",
    "import plotly\n",
    "import plotly.offline as py\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "import plotly.graph_objs as go\n",
    "from plotly import tools\n",
    "init_notebook_mode(connected = True)\n",
    "import plotly.figure_factory as ff\n",
    "\n",
    "# for animated visualizations\n",
    "from bubbly.bubbly import bubbleplot\n",
    "\n",
    "# for providing path\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "\n",
    "# for modelling\n",
    "import sklearn\n",
    "import imblearn\n",
    "\n",
    "# for model explanation\n",
    "import shap \n",
    "import eli5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f5b6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's import the data\n",
    "data = pd.read_csv('../input/insurance_claims.csv')\n",
    "\n",
    "# let's take a look at the data\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e902b142",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's take a look at the sample of the data\n",
    "\n",
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485d33ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's check the shape of the dataset\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21034045",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's describe the data\n",
    "# It will demonstrate the count, mean, std dev, min, max, etc values for the Numerical features present in the data.\n",
    "\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6567ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's get the information about the dataset\n",
    "\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ae81b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's check whether the data has any null values or not.\n",
    "\n",
    "# but there are '?' in the datset which we have to remove by NaN Values\n",
    "data = data.replace('?',np.NaN)\n",
    "\n",
    "data.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e640835",
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing value treatment using fillna\n",
    "\n",
    "# we will replace the '?' by the most common collision type as we are unaware of the type.\n",
    "data['collision_type'].fillna(data['collision_type'].mode()[0], inplace = True)\n",
    "\n",
    "# It may be the case that there are no responses for property damage then we might take it as No property damage.\n",
    "data['property_damage'].fillna('NO', inplace = True)\n",
    "\n",
    "# again, if there are no responses fpr police report available then we might take it as No report available\n",
    "data['police_report_available'].fillna('NO', inplace = True)\n",
    "\n",
    "data.isnull().any().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d738d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud = data['fraud_reported'].value_counts()\n",
    "\n",
    "label_fraud = fraud.index\n",
    "size_fraud = fraud.values\n",
    "\n",
    "colors = ['silver', 'gold']\n",
    "trace = go.Pie(\n",
    "         labels = label_fraud, values = size_fraud, marker = dict(colors = colors), name = 'Frauds', hole = 0.3)\n",
    "\n",
    "\n",
    "df = [trace]\n",
    "\n",
    "layout = go.Layout(\n",
    "           title = 'Distribution of Frauds')\n",
    "\n",
    "fig = go.Figure(data = df, layout = layout)\n",
    "\n",
    "py.iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b1e8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = joypy.joyplot(data,\n",
    "                         column = ['incident_hour_of_the_day','number_of_vehicles_involved', 'witnesses'],\n",
    "                         by = 'incident_city',\n",
    "                         ylim = 'own',\n",
    "                         figsize = (20, 10),\n",
    "                         alpha = 0.5, \n",
    "                         legend = True)\n",
    "\n",
    "plt.title('Incident hour, No. of vehicles, witnesses vs Incident City', fontsize = 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d263efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('fivethirtyeight')\n",
    "plt.rcParams['figure.figsize'] = (15, 8)\n",
    "\n",
    "sns.stripplot(data['property_damage'], data['property_claim'], palette = 'bone')\n",
    "plt.title('Incident Type vs Vehicle Claim', fontsize = 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1cbf95",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('fivethirtyeight')\n",
    "plt.rcParams['figure.figsize'] = (15, 8)\n",
    "\n",
    "sns.boxenplot(data['incident_type'], data['vehicle_claim'], palette = 'pink')\n",
    "plt.title('Incident Type vs Vehicle Claim', fontsize = 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d67bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "incident = pd.crosstab(data['incident_city'], data['incident_type'])\n",
    "colors = plt.cm.Blues(np.linspace(0, 1, 5))\n",
    "incident.div(incident.sum(1).astype(float), axis = 0).plot(kind = 'bar',\n",
    "                                                           stacked = False,\n",
    "                                                           figsize = (15, 7),\n",
    "                                                           color = colors)\n",
    "\n",
    "plt.title('Incident Type vs Collision Type', fontsize = 20)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88455e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "incident = pd.crosstab(data['incident_type'], data['incident_severity'])\n",
    "colors = plt.cm.summer(np.linspace(0, 1, 5))\n",
    "incident.div(incident.sum(1).astype(float), axis = 0).plot(kind = 'bar',\n",
    "                                                           stacked = False,\n",
    "                                                           figsize = (15, 7),\n",
    "                                                           color = colors)\n",
    "\n",
    "plt.title('Incident Type vs Collision Type', fontsize = 20)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a0c886",
   "metadata": {},
   "outputs": [],
   "source": [
    "incident = pd.crosstab(data['incident_type'], data['collision_type'])\n",
    "colors = plt.cm.inferno(np.linspace(0, 1, 5))\n",
    "incident.div(incident.sum(1).astype(float), axis = 0).plot(kind = 'bar',\n",
    "                                                           stacked = True,\n",
    "                                                           figsize = (15, 7),\n",
    "                                                           color = colors)\n",
    "\n",
    "plt.title('Incident Type vs Collision Type', fontsize = 20)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431da1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's check the insured hobbies\n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "plt.rcParams['figure.figsize'] = (15, 8)\n",
    "\n",
    "sns.countplot(data['insured_occupation'], palette = 'PuRd')\n",
    "plt.title('Different Types of Occupation of Insured Customers', fontsize = 20)\n",
    "plt.xticks(rotation = 90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3437e889",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's check the insured hobbies\n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "plt.rcParams['figure.figsize'] = (15, 8)\n",
    "\n",
    "sns.countplot(data['insured_hobbies'], palette = 'cool')\n",
    "plt.title('Different Types of Hobbies of Insured Customers', fontsize = 20)\n",
    "plt.xticks(rotation = 90)\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e99810",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's check the incident types\n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "plt.rcParams['figure.figsize'] = (15, 8)\n",
    "\n",
    "sns.countplot(data['incident_type'], palette = 'spring')\n",
    "plt.title('Different Types of Incidents', fontsize = 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4765d03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# swarm plot\n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "plt.rcParams['figure.figsize'] = (15, 8)\n",
    "\n",
    "sns.swarmplot(data['policy_state'], data['total_claim_amount'], palette = 'copper')\n",
    "plt.title('Policy State vs Total Claim Amount', fontsize = 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e9dbeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "plt.figure(figsize=(20, 10), dpi= 80)\n",
    "\n",
    "parallel_coordinates(data[['total_claim_amount','injury_claim', 'property_claim','vehicle_claim','fraud_reported']],\n",
    "                     'fraud_reported',  colormap = 'copper')\n",
    "\n",
    "# Lighten borders\n",
    "plt.gca().spines[\"top\"].set_alpha(0)\n",
    "plt.gca().spines[\"bottom\"].set_alpha(.3)\n",
    "plt.gca().spines[\"right\"].set_alpha(0)\n",
    "plt.gca().spines[\"left\"].set_alpha(.3)\n",
    "\n",
    "plt.title('DC', fontsize = 20)\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "\n",
    "plt.suptitle('total claim, Injury claim, Property claim, vehicle claim vs Fraud Reported', fontsize = 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8d4133",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "figure = bubbleplot(dataset = data, x_column = 'policy_annual_premium', y_column = 'total_claim_amount', \n",
    "    bubble_column = 'insured_sex', time_column = 'auto_year', size_column = 'months_as_customer', color_column = 'insured_sex', \n",
    "    x_title = \"Annual Policy Premium\", y_title = \"Total Claim Amount\", title = 'Annual Premium vs Total Claim Amount vs Months as Customer',\n",
    "    x_logscale = False, scale_bubble = 3, height = 650)\n",
    "\n",
    "py.iplot(figure, config={'scrollzoom': True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b39709b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trace = go.Histogram(\n",
    "          x = data['insured_education_level'],\n",
    "          name = 'Marvel',\n",
    "          opacity = 0.75,\n",
    "          marker = dict(\n",
    "                 color = 'rgb(195, 195, 145, 0.5)'\n",
    "          )\n",
    ")\n",
    "df = [trace]\n",
    "\n",
    "layout = go.Layout(\n",
    "    title = 'Education Level of the Customers')\n",
    "\n",
    "fig = go.Figure(data = df, layout = layout)\n",
    "py.iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3b6256",
   "metadata": {},
   "outputs": [],
   "source": [
    "trace = go.Histogram(\n",
    "          x = data['insured_occupation'],\n",
    "          name = 'Marvel',\n",
    "          opacity = 0.75,\n",
    "          marker = dict(\n",
    "                 color = 'rgb(15, 255, 185, 0.5)'\n",
    "          )\n",
    ")\n",
    "df = [trace]\n",
    "\n",
    "layout = go.Layout(\n",
    "    title = 'Occupation of the Customers')\n",
    "\n",
    "fig = go.Figure(data = df, layout = layout)\n",
    "py.iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9262ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "sex = data['insured_sex'].value_counts()\n",
    "rel = data['insured_relationship'].value_counts()\n",
    "\n",
    "label_sex = sex.index\n",
    "size_sex = sex.values\n",
    "\n",
    "label_rel = rel.index\n",
    "size_rel = rel.values\n",
    "\n",
    "colors = ['aqua', 'gold']\n",
    "trace = go.Pie(\n",
    "         labels = label_sex, values = size_sex, marker = dict(colors = colors), name = 'Gender', hole = 0.3)\n",
    "\n",
    "colors2 = ['pink', 'lightblue','lightgreen','grey','red']\n",
    "trace2 = go.Pie(labels = label_rel, values = size_rel, marker = dict(colors = colors2), name = 'Relationship',\n",
    "                hole = 0.3)\n",
    "\n",
    "df = [trace]\n",
    "df2 = [trace2]\n",
    "\n",
    "layout1 = go.Layout(\n",
    "           title = 'Gender of the Customers')\n",
    "layout2 = go.Layout(\n",
    "           title = 'Relationship')\n",
    "\n",
    "fig = go.Figure(data = df, layout = layout1)\n",
    "fig2 = go.Figure(data = df2, layout = layout2)\n",
    "py.iplot(fig)\n",
    "py.iplot(fig2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27430cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "trace = go.Violin(\n",
    "          x = data['insured_sex'],\n",
    "          y = data['insured_zip'],\n",
    "          name = 'Gender vs Insured Zip',\n",
    "          opacity = 0.75,\n",
    "          marker = dict(\n",
    "                 color = 'rgb(215, 5, 185, 0.5)'\n",
    "          )\n",
    ")\n",
    "df = [trace]\n",
    "\n",
    "layout = go.Layout(\n",
    "    title = 'Gender vs Insured Zip')\n",
    "\n",
    "fig = go.Figure(data = df, layout = layout)\n",
    "py.iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd014c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "trace = go.Box(\n",
    "          x = data['auto_make'],\n",
    "          y = data['vehicle_claim'],\n",
    "          opacity = 0.7,\n",
    "          marker = dict(\n",
    "                 color = 'rgb(215, 195, 5, 0.5)'\n",
    "          )\n",
    ")\n",
    "df = [trace]\n",
    "\n",
    "layout = go.Layout(\n",
    "    title = 'Automobile Company vs Vehicle Claim')\n",
    "\n",
    "fig = go.Figure(data = df, layout = layout)\n",
    "py.iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725be075",
   "metadata": {},
   "outputs": [],
   "source": [
    "trace = go.Histogram(\n",
    "          x = data['policy_annual_premium'],\n",
    "          \n",
    "          #fill = 'tozeroy',\n",
    "          marker = dict(\n",
    "                 color = 'rgb(100, 75, 25, 0.5)'\n",
    "          )\n",
    ")\n",
    "df = [trace]\n",
    "\n",
    "layout = go.Layout(\n",
    "    title = 'Distribution of Annual Policy among the Customers',\n",
    "    scene = dict(\n",
    "            xaxis = dict(title  = 'Age'),\n",
    "            yaxis = dict(title  = 'Count')\n",
    "        ))\n",
    "\n",
    "fig = go.Figure(data = df, layout = layout)\n",
    "py.iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4aa888",
   "metadata": {},
   "outputs": [],
   "source": [
    "trace = go.Histogram(\n",
    "          x = data['age'],\n",
    "          \n",
    "          #fill = 'tozeroy',\n",
    "          marker = dict(\n",
    "                 color = 'rgb(215, 245, 5, 0.5)'\n",
    "          )\n",
    ")\n",
    "df = [trace]\n",
    "\n",
    "layout = go.Layout(\n",
    "    title = 'Distribution of Age among the Customers',\n",
    "    scene = dict(\n",
    "            xaxis = dict(title  = 'Age'),\n",
    "            yaxis = dict(title  = 'Count')\n",
    "        ))\n",
    "\n",
    "fig = go.Figure(data = df, layout = layout)\n",
    "py.iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63bff6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "trace = go.Scatter3d(\n",
    "    x = data['age'],\n",
    "    y = data['property_claim'],\n",
    "    z = data['vehicle_claim'],\n",
    "    mode = 'markers',\n",
    "    marker = dict(\n",
    "         size = 10,\n",
    "         color = data['age']\n",
    "    )\n",
    ")\n",
    "\n",
    "df = [trace]\n",
    "\n",
    "layout = go.Layout(\n",
    "    title = 'Cholestrol vs Heart Rate vs Age',\n",
    "    margin=dict(\n",
    "        l=0,\n",
    "        r=0,\n",
    "        b=0,\n",
    "        t=0  \n",
    "    ),\n",
    "    scene = dict(\n",
    "            xaxis = dict(title  = 'Age'),\n",
    "            yaxis = dict(title  = 'Property_claim'),\n",
    "            zaxis = dict(title  = 'Vehicle_claim')\n",
    "        )\n",
    "    \n",
    ")\n",
    "fig = go.Figure(data = df, layout=layout)\n",
    "py.iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2861000",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's extrat days, month and year from policy bind date\n",
    "\n",
    "data['policy_bind_date'] = pd.to_datetime(data['policy_bind_date'], errors = 'coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a191624",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's encode the fraud report to numerical values\n",
    "\n",
    "data['fraud_reported'] = data['fraud_reported'].replace(('Y','N'),(0,1))\n",
    "\n",
    "# checking the values of fraud reported\n",
    "# data['fraud_reported'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0efe0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's check the correlation of authorities_contacted with the target\n",
    "\n",
    "data[['auto_model','fraud_reported']].groupby(['auto_model'], \n",
    "                as_index = False).mean().sort_values(by = 'fraud_reported', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e6b208",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's perform target encoding for auto make\n",
    "\n",
    "data['auto_make'] = data['auto_make'].replace(('3 Series','RSX','Malibu','Wrangler','Pathfinder','Ultima','Camry',\n",
    "                'Corolla','CRV','Legacy','Neon','95','TL','93','MDX','Accord','Grand Cherokee','Escape','E4000',\n",
    "            'A3','Highlander','Passat','92x','Jetta','Fusion','Forrestor','Maxima','Impreza','X5','RAM','M5','A5',\n",
    "                'Civic','F150','Tahaoe','C300','ML350','Silverado','X6'),\n",
    "                (0.95,0.91, 0.90,0.88,0.87,0.86,0.855,0.85,0.85,0.84,0.83,0.81,0.80,0.80,0.78,0.77,0.76,0.75,0.74,\n",
    "                 0.73,0.72,0.72,0.71,0.71,0.71,0.71,0.70,0.70,0.69,0.67,0.66,0.65,0.64,0.63,0.62,0.61,0.60,0.59,0.56))\n",
    "\n",
    "# let's check the values\n",
    "# data['auto_make'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e458641b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's check the correlation auto make with the target\n",
    "\n",
    "data[['auto_make','fraud_reported']].groupby(['auto_make'], \n",
    "                as_index = False).mean().sort_values(by = 'fraud_reported', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe9cfb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's perform target encoding for auto make\n",
    "\n",
    "data['auto_make'] = data['auto_make'].replace(('Jeep','Nissan','Toyota','Accura','Saab','Suburu',\n",
    "                                'Dodge','Honda','Chevrolet','BMW','Volkswagen','Audi','Ford','Mercedes'),\n",
    "                                              (0.84,0.82,0.81,0.80,0.77,0.76,0.75,0.74,0.73,0.72,0.71,0.69,0.69,0.66))\n",
    "\n",
    "# let's check the values\n",
    "# data['auto_make'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5321d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# let's check the correlation of authorities_contacted with the target\n",
    "\n",
    "data[['police_report_available','fraud_reported']].groupby(['police_report_available'], \n",
    "                as_index = False).mean().sort_values(by = 'fraud_reported', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66fb2370",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's perform target encoding for property damage\n",
    "\n",
    "data['police_report_available'] = data['police_report_available'].replace(('NO','YES'),(0.77,0.74))\n",
    "\n",
    "# let's check the values\n",
    "# data['police_report_available'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0aa0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's check the correlation of authorities_contacted with the target\n",
    "\n",
    "data[['property_damage','fraud_reported']].groupby(['property_damage'], \n",
    "                as_index = False).mean().sort_values(by = 'fraud_reported', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5be7057",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's perform target encoding for property damage\n",
    "\n",
    "data['property_damage'] = data['property_damage'].replace(('NO','YES'),(0.76,0.74))\n",
    "\n",
    "# let's check the values\n",
    "# data['property_damage'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80714283",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's check the correlation of authorities_contacted with the target\n",
    "\n",
    "data[['incident_city','fraud_reported']].groupby(['incident_city'], \n",
    "                as_index = False).mean().sort_values(by = 'fraud_reported', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cabd76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's do target encoding for incident city\n",
    "\n",
    "data['incident_city'] = data['incident_city'].replace(('Northbrook','Riverwood','Northbend','Springfield',\n",
    "                                    'Hillsdale','Columbus','Arlington'),(0.78,0.77,0.76,0.75,0.74,0.73,0.71))\n",
    "\n",
    "# let's check the values\n",
    "# data['incident_city'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b831eb62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's check the correlation of authorities_contacted with the target\n",
    "\n",
    "data[['incident_state','fraud_reported']].groupby(['incident_state'], \n",
    "                as_index = False).mean().sort_values(by = 'fraud_reported', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66573da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's perform target encoding for incident state\n",
    "\n",
    "data['incident_state'] = data['incident_state'].replace(('WV','NY','VA','PA','SC','NC','OH'),\n",
    "                                                        (0.82,0.77,0.76,0.73,0.70,0.69,0.56))\n",
    "\n",
    "# checking the values\n",
    "# data['incident_state'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d81ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's check the correlation of authorities_contacted with the target\n",
    "\n",
    "data[['authorities_contacted','fraud_reported']].groupby(['authorities_contacted'], \n",
    "                as_index = False).mean().sort_values(by = 'fraud_reported', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b480d114",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "authorities_contacted\tfraud_reported\n",
    "2\tNone\t0.934066\n",
    "4\tPolice\t0.791096\n",
    "1\tFire\t0.730942\n",
    "0\tAmbulance\t0.709184\n",
    "3\tOther\t0.681818\n",
    "# let's perform target encoding for authorities contacted\n",
    "\n",
    "data['authorities_contacted'] = data['authorities_contacted'].replace(('None','Police','Fire','Ambulance','Other'),\n",
    "                                                                      (0.94,0.79,0.73,0.70,0.68))\n",
    "\n",
    "# let's check the values\n",
    "#data['authorities'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0325dda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's check the correlation of incident_severity with the target\n",
    "\n",
    "data[['incident_severity','fraud_reported']].groupby(['incident_severity'], \n",
    "                as_index = False).mean().sort_values(by = 'fraud_reported', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8207554",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's perform target encoding for incident severity\n",
    "\n",
    "data['incident_severity'] = data['incident_severity'].replace(('Trivial Damage','Minor Damage','Total Loss',\n",
    "                                                              'Major Damage'),(0.94,0.89,0.87,0.39))\n",
    "\n",
    "# let's check the values\n",
    "# data['incident_severity'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2261d0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's check the correlation of collision_type with the target\n",
    "\n",
    "data[['collision_type','fraud_reported']].groupby(['collision_type'], \n",
    "                as_index = False).mean().sort_values(by = 'fraud_reported', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547c75ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's perform target encoding for collision type\n",
    "\n",
    "data['collision_type'] = data['collision_type'].replace(('Rear Collision', 'Side Collision', 'Front Collision'),\n",
    "                                                        (0.78,0.74,0.72))\n",
    "\n",
    "# let's check the values of collision type\n",
    "# data['collision_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14ccf30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's check the correlation of incident_type with the target\n",
    "\n",
    "data[['incident_type','fraud_reported']].groupby(['incident_type'], \n",
    "                as_index = False).mean().sort_values(by = 'fraud_reported', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87bb854a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's perform target encoing for incident type\n",
    "\n",
    "data['incident_type'] = data['incident_type'].replace(('Vehicle Theft','Parked Car','Multi-vehicle Collision',\n",
    "                                'Single Vehicle Collision'),(0.91, 0.90, 0.72,0.70))\n",
    "\n",
    "# let's check the values\n",
    "#data['incident_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a290aed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['incident_date'] = pd.to_datetime(data['incident_date'], errors = 'coerce')\n",
    "\n",
    "# extracting days and month from date\n",
    "data['incident_month'] = data['incident_date'].dt.month\n",
    "data['incident_day'] = data['incident_date'].dt.day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87abde4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's know the relation between insured_relationship and fraud reported\n",
    "\n",
    "data[['insured_relationship','fraud_reported']].groupby(['insured_relationship'], \n",
    "                as_index = False).mean().sort_values(by = 'fraud_reported', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d59d90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's do target encoding for insured relationship\n",
    "\n",
    "data['insured_relationship'] = data['insured_relationship'].replace(('husband','own-child','unmarried',\n",
    "                                        'not-in-family','wife','other-relative'),(0.79,0.78,0.75,0.74,0.72,0.70))\n",
    "\n",
    "#data['insured-relationship'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9111c077",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's know the relation between insured_hobbies and fraud reported\n",
    "\n",
    "data[['insured_hobbies','fraud_reported']].groupby(['insured_hobbies'], \n",
    "                as_index = False).mean().sort_values(by = 'fraud_reported', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfb068e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's perform target encoding for insured_hobbies\n",
    "\n",
    "data['insured_hobbies'] = data['insured_hobbies'].replace(('camping', 'kayaking', 'golf','dancing',\n",
    "        'bungie-jumping','movies', 'basketball','exercise','sleeping','video-games','skydiving','paintball',\n",
    "            'hiking','base-jumping','reading','polo','board-games','yachting', 'cross-fit','chess'),(0.91, 0.90,\n",
    "                0.89, 0.88,0.84,0.83,0.82,0.81,0.805,0.80,0.78,0.77,0.76,0.73,0.73,0.72,0.70,0.69,0.25,0.17))\n",
    "\n",
    "#data['insured_hobbies'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a97bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's know the relation between insured_occupation and fraud reported\n",
    "\n",
    "data[['insured_occupation','fraud_reported']].groupby(['insured_occupation'], \n",
    "                as_index = False).mean().sort_values(by = 'fraud_reported', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae44911",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's perform target encoding for insured_occupation\n",
    "\n",
    "data['insured_occupation'] = data['insured_occupation'].replace(('other-service','priv-house-serv',\n",
    "                        'adm-clerical','handlers-cleaners','prof-specialty','protective-serv',\n",
    "                'machine-op-inspct','armed-forces','sales','tech-support','transport-moving','craft-repair',\n",
    "                    'farming-fishing','exec-managerial'),(0.84, 0.84,0.83, 0.79,0.78,0.77,0.76,0.75,0.72,0.71,\n",
    "                                                          0.705,0.70,0.69,0.63))\n",
    "# data['insured_occupation'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d9176f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's know the relation of insured_education_level with faud_reported\n",
    "\n",
    "data[['insured_education_level','fraud_reported']].groupby(['insured_education_level'], \n",
    "                as_index = False).mean().sort_values(by = 'fraud_reported', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce344e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's perform target encoding\n",
    "\n",
    "data['insured_education_level'] = data['insured_education_level'].replace(('Masters', 'High School','Associate',\n",
    "                                        'JD','College', 'MD','PhD'),(0.78,0.77,0.76,0.74,0.73,0.72,0.71))\n",
    "#data['insured_education_level'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2805d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets know the relation of insured sex and fraud reported\n",
    "\n",
    "data[['insured_sex','fraud_reported']].groupby(['insured_sex'], as_index = False).mean().sort_values(\n",
    "    by = 'fraud_reported', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f91897",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target encoding for sex\n",
    "\n",
    "data['insured_sex'] = data['insured_sex'].replace(('FEMALE','MALE'),(0.76,0.73))\n",
    "#data['insured_sex'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9798d92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# csl - combined single limit\n",
    "\n",
    "'''CSL is a single number that describes the predetermined limit for the combined total of the Bodily Injury \n",
    "Liability coverage and Property Damage Liability coverage per occurrence or accident.'''\n",
    "\n",
    "# lets know the relation of policy state and fraud reported\n",
    "\n",
    "data[['policy_csl','fraud_reported']].groupby(['policy_csl'], as_index = False).mean().sort_values(\n",
    "    by = 'fraud_reported', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ef0853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target encoding for policy_csl\n",
    "\n",
    "data['policy_csl'] = data['policy_csl'].replace(('500/1000','100/300','250/500'),(0.78,0.74,0.73))\n",
    "\n",
    "# check the values\n",
    "# data['policy_csl'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367646c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets know the relation of policy state and fraud reported\n",
    "\n",
    "data[['policy_state','fraud_reported']].groupby(['policy_state'], as_index = False).mean().sort_values(\n",
    "    by = 'fraud_reported', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fded07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target encoding for policy_csl\n",
    "\n",
    "data['policy_state'] = data['policy_state'].replace(('IL','IN','OH'),(0.77,0.745,0.74))\n",
    "\n",
    "# check the values\n",
    "# data['policy_state'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9c0835",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's delete unnecassary columns\n",
    "\n",
    "data = data.drop(['policy_number','policy_bind_date', 'incident_date','incident_location','auto_model'], axis = 1)\n",
    "\n",
    "# let's check the columns after deleting the columns\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669f5617",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's split the data into dependent and independent sets\n",
    "\n",
    "x = data.drop(['fraud_reported'], axis = 1)\n",
    "y = data['fraud_reported']\n",
    "\n",
    "print(\"Shape of x :\", x.shape)\n",
    "print(\"Shape of y :\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4b84db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's split the dataset into train and test sets\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 0)\n",
    "\n",
    "print(\"Shape of x_train :\", x_train.shape)\n",
    "print(\"Shape of x_test :\", x_test.shape)\n",
    "print(\"Shape of y_train :\", y_train.shape)\n",
    "print(\"Shape of y_test :\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd711d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (15, 10)\n",
    "sns.heatmap(x_train.corr(), cmap = 'copper')\n",
    "plt.title('Heat Map for Correlations', fontsize = 20)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
